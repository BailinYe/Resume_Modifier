````markdown
# ğŸš€ Resume Modifier - AI-Powered Resume Optimization Platform

[![100% Test Coverage](https://img.shields.io/badge/tests-67%2F67%20passing-brightgreen)](https://github.com/Andrlulu/Resume_Modifier)
[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/)
[![Flask](https://img.shields.io/badge/framework-Flask-red.svg)](https://flask.palletsprojects.com/)
[![OpenAI GPT-4](https://img.shields.io/badge/AI-OpenAI%20GPT--4-orange.svg)](https://openai.com/)
[![PostgreSQL](https://img.shields.io/badge/database-PostgreSQL-blue.svg)](https://www.postgresql.org/)

## ğŸ¯ Project Overview

Resume Modifier is a comprehensive web service that leverages artificial intelligence to help users optimize their resumes for job applications. Built with modern technologies and following best practices, it offers:

### âœ¨ Key Features
- **ğŸ” AI-Powered Resume Analysis**: Deep analysis using OpenAI GPT-4 models
- **ğŸ“„ PDF Resume Parsing**: Intelligent extraction of resume content from PDF files
- **ğŸ“ File Management System**: Complete file upload, download, processing, and storage with support for PDF and DOCX formats
- **â˜ï¸ Multi-Storage Support**: Local file storage and Amazon S3 cloud storage with automatic failover
- **ğŸ¯ Job-Specific Optimization**: Tailored suggestions based on job descriptions
- **ğŸ“Š Comprehensive Scoring**: Multi-dimensional scoring with detailed metrics
- **ğŸ” Secure Authentication**: JWT-based user authentication and authorization
- **ğŸ“± Interactive API**: Complete RESTful API with Swagger documentation
- **ğŸš€ Export Capabilities**: Multi-format export (PDF, DOCX, Google Docs)
- **â˜ï¸ Google Integration**: Full Google OAuth and Drive API integration
- **ğŸ¨ Professional Templates**: Responsive design templates with professional styling
- **ğŸ›¡ï¸ Advanced Error Handling**: Centralized error management with user-friendly messages and comprehensive logging

### ğŸ—ï¸ Architecture Highlights
- **100% Test Coverage**: 67/67 tests passing with comprehensive TDD approach
- **Production-Ready**: Docker containerization with multi-environment support
- **Scalable Design**: Service-layer architecture with clean separation of concerns
- **Database Management**: PostgreSQL with proper migrations and relationships
- **API Documentation**: Complete OpenAPI/Swagger specification

## ğŸ“š Complete Documentation Suite

### ğŸ”— Quick Access Links
- **ğŸŒ Interactive API Docs**: `http://localhost:5001/apidocs` (when running locally)
- **âš¡ Quick Setup**: Run `./setup.sh` for automated local setup
- **ğŸš„ Railway Deploy**: [![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/template/deploy?referrer=github)
- **ğŸ—„ï¸ Database Test**: Run `python3 test_database.py` to verify database setup

### ğŸ“– Detailed Documentation
| Document | Description | Use Case |
|----------|-------------|----------|
| [ğŸ“– API_DOCUMENTATION.md](./API_DOCUMENTATION.md) | Complete API reference with examples | API integration, development |
| [ğŸš€ DEPLOYMENT_GUIDE.md](./DEPLOYMENT_GUIDE.md) | Local & production deployment | DevOps, setup |
| [ğŸ—„ï¸ DATABASE_SETUP_TROUBLESHOOTING.md](./DATABASE_SETUP_TROUBLESHOOTING.md) | Database setup and troubleshooting guide | Database issues, setup problems |
| [ğŸš„ RAILWAY_DEPLOYMENT.md](./RAILWAY_DEPLOYMENT.md) | Railway-specific deployment guide | Cloud deployment |
| [ğŸ“Š TASK_TRACKING.md](./TASK_TRACKING.md) | Development progress & achievements | Project status |

### ğŸ—„ï¸ Database Management Documentation
| Document | Description | Use Case |
|----------|-------------|----------|
| [ğŸ‰ MIGRATION_ALIGNMENT_COMPLETE.md](./MIGRATION_ALIGNMENT_COMPLETE.md) | Migration sync completion report | Understanding what was fixed |
| [ğŸ“Š DATABASE_REVIEW_SUMMARY.md](./DATABASE_REVIEW_SUMMARY.md) | Current database state & issues | Understanding current setup |
| [ğŸ” DATABASE_ANALYSIS.md](./DATABASE_ANALYSIS.md) | Detailed technical database analysis | Deep dive into schema |
| [ğŸ“š docs/DATABASE_BEST_PRACTICES.md](./docs/DATABASE_BEST_PRACTICES.md) | Complete migration & management guide | Development & production workflows |
| [ğŸš€ docs/DEPLOYMENT_WORKFLOW.md](./docs/DEPLOYMENT_WORKFLOW.md) | Step-by-step deployment cheat sheet | Deploying database changes |
| [ğŸ“˜ docs/DATABASE_QUICKSTART.md](./docs/DATABASE_QUICKSTART.md) | Quick start guide | Getting started fast |

### ğŸ› ï¸ Database Scripts & Tools
| Script | Description | Use Case |
|--------|-------------|----------|
| [ğŸ”§ verify_database_schema.py](./verify_database_schema.py) | Schema verification script | Checking database integrity |
| [âœ… validate_migrations.py](./validate_migrations.py) | Migration validation script | Verify migrations before deploy |
| [âš¡ fix_database_primary_keys.sh](./fix_database_primary_keys.sh) | Fix missing primary keys | Resolving PK issues (already applied) |

## ğŸš€ Quick Start

### Prerequisites
- ğŸ³ Docker and Docker Compose installed
- ğŸ”‘ OpenAI API key ([Get one here](https://platform.openai.com/account/api-keys))
- ğŸ’» Python 3.12+ (for local development)
- ğŸ—„ï¸ PostgreSQL (handled by Docker)

### âš ï¸ Database Configuration Notice
**Important**: This project is configured for PostgreSQL. If you encounter database connection issues, run:
```bash
python3 test_database.py
```
See [DATABASE_SETUP_TROUBLESHOOTING.md](./DATABASE_SETUP_TROUBLESHOOTING.md) for detailed troubleshooting steps.

### ğŸ“¥ Installation

1. **Clone the Repository**
   ```bash
   git clone https://github.com/Andrlulu/Resume_Modifier.git
   cd Resume_Modifier
   ```

2. **Environment Setup**
   ```bash
   # Copy example environment file
   cp .env.example .env
   
   # Edit .env with your credentials
   nano .env  # or use your preferred editor
   ```

3. **Required Environment Variables**
   ```bash
   # OpenAI Configuration
   OPENAI_API_KEY=sk-proj-your-openai-api-key-here
   
   # Database Configuration
   DATABASE_URL=postgresql://postgres:postgres@db:5432/resume_app
   
   # JWT Security
   JWT_SECRET=your-super-secure-jwt-secret-key-here
   
   # Flask Configuration
   FLASK_APP=app.server
   FLASK_ENV=development
   FLASK_DEBUG=1
   ```

## ğŸ³ Running with Docker (Recommended)

### Development Environment
```bash
# Build and start all services
docker compose up --build

# Run in background
docker compose up -d --build

# View logs
docker compose logs -f web
```

### ğŸ¯ Access Points
- **API Base URL**: http://localhost:5001
- **Interactive API Docs**: http://localhost:5001/apidocs
- **Health Check**: http://localhost:5001/health
- **Database**: localhost:5432

### ğŸ›‘ Stopping Services
```bash
# Stop containers
docker compose down

# Stop and remove all data (including database)
docker compose down -v

# Rebuild from scratch
docker compose down -v && docker compose up --build
```

## ğŸ’» Local Development Setup

### Without Docker
```bash
# 1. Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 2. Install dependencies
pip install -r requirements.txt

# 3. Set up PostgreSQL locally
# Database: resume_app
# Username: postgres
# Password: postgres

# 4. Run database migrations
flask db upgrade

# 5. Start development server
python -m app.server
```

### With Docker for Database Only
```bash
# Start only database service
docker compose up db -d

# Run Flask app locally
export DATABASE_URL=postgresql://postgres:postgres@localhost:5432/resume_app
python -m app.server
```

## ğŸ”— API Endpoints Overview

### ğŸŒ Public Endpoints
| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/health` | System health check |
| `POST` | `/api/register` | User registration |
| `POST` | `/api/login` | User authentication |
| `POST` | `/api/pdfupload` | PDF resume parsing |
| `POST` | `/api/job_description_upload` | Resume analysis |
| `POST` | `/api/resume/score` | AI-powered resume scoring |

### ğŸ” Protected Endpoints (JWT Required)
| Method | Endpoint | Description |
|--------|----------|-------------|
| `PUT` | `/api/save_resume` | Save/update resume |
| `GET` | `/api/get_resume_list` | List user resumes |
| `GET` | `/api/get_resume/<id>` | Get specific resume |
| `PUT` | `/api/put_profile` | Update user profile |
| `GET` | `/api/get_profile` | Get user profile |

### ğŸ¨ Export & Google Integration
| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/export/google-docs` | Export to Google Docs |
| `POST` | `/api/export/pdf` | Export to PDF |
| `POST` | `/api/export/docx` | Export to DOCX |
| `GET` | `/api/auth/google` | Google OAuth flow |

## ğŸ§ª Testing

### Automated Test Suite (100% Coverage)
```bash
# Run all tests
pytest app/tests/ -v

# Run with coverage report
pytest app/tests/ --cov=app --cov-report=html

# Run specific test categories
pytest app/tests/test_resume_ai.py -v
pytest app/tests/test_google_integration.py -v
pytest app/tests/test_server.py -v
```

### Manual API Testing
```bash
# Quick API test script
python test_api.py

# Test individual endpoints
curl -X GET http://localhost:5001/health
curl -X GET http://localhost:5001/apidocs
```

## ğŸš„ Railway Deployment

### ğŸš€ Quick Deploy (5 minutes)

[![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/new/template)

**New to Railway?** Follow our step-by-step guides:

| Guide | Time | Purpose |
|-------|------|---------|
| ğŸ“– [**Railway Docs Index**](./RAILWAY_DOCS_INDEX.md) | 2 min | Start here - Choose your guide |
| âš¡ [**Quick Deploy**](./RAILWAY_QUICK_DEPLOY.md) | 5 min | Fast deployment reference |
| ğŸ“š [**Complete Guide**](./RAILWAY_DEPLOYMENT_COMPLETE_GUIDE.md) | 60 min | Production-ready deployment |
| ğŸ”„ [**Migration Guide**](./RAILWAY_MIGRATION_GUIDE.md) | 15 min | Database migration help |

### Essential Steps

1. **Create Railway Account** at [railway.app](https://railway.app)

2. **Deploy from GitHub**
   ```bash
   # Connect your GitHub repository to Railway
   # Railway auto-detects Python and uses railway.toml
   ```

3. **Add PostgreSQL Database**
   ```bash
   # In Railway Dashboard:
   # Click "New" â†’ "Database" â†’ "PostgreSQL"
   ```

4. **Set Environment Variables**
   ```bash
   OPENAI_API_KEY=sk-proj-your-openai-key-here
   JWT_SECRET=your-super-secure-jwt-secret
   FLASK_SECRET_KEY=your-flask-secret
   FLASK_APP=app.server
   FLASK_ENV=production
   PORT=5001
   ```

5. **Run Database Migration**
   ```bash
   # Option A: Automated (recommended)
   # Update railway.toml startCommand to include migration
   
   # Option B: Manual
   ./scripts/railway_migrate.py upgrade
   ```

6. **Verify Deployment**
   ```bash
   curl https://your-app.railway.app/health
   # Expected: {"status": "healthy", ...}
   ```

### ğŸ› ï¸ Automated Migration Scripts

We provide automated tools for easy database migrations:

```bash
# Python script (recommended)
./scripts/railway_migrate.py upgrade
./scripts/railway_migrate.py current

# Bash script (alternative)
./scripts/railway_migrate.sh upgrade
```

**See:** [scripts/README.md](./scripts/README.md) for detailed usage

### âš ï¸ Important Notes

- **Database URLs**: Railway provides two URLs (internal & public)
  - Use **internal** for deployed apps (automatic)
  - Use **public** for local migrations
  - See [Migration Guide](./RAILWAY_MIGRATION_GUIDE.md) for details

- **Environment Variables**: Generate secure secrets:
  ```bash
  openssl rand -base64 32  # For JWT_SECRET
  openssl rand -base64 32  # For FLASK_SECRET_KEY
  ```

- **Google OAuth**: Update redirect URI to match your Railway URL:
  ```
  https://your-app.railway.app/auth/google/callback
  ```

### ğŸ“š Comprehensive Documentation

For detailed deployment instructions, troubleshooting, security best practices, CI/CD setup, and more:

**ğŸ‘‰ [View Complete Railway Documentation](./RAILWAY_DOCS_INDEX.md)**

## ğŸ—„ï¸ Database Management

### Local Development
```bash
# View Docker volumes
docker volume ls

# Backup database
docker compose exec db pg_dump -U postgres resume_app > backup.sql

# Restore database
docker compose exec -T db psql -U postgres resume_app < backup.sql

# Database shell access
docker compose exec db psql -U postgres resume_app
```

### Production (Railway)
```bash
# Connect to Railway PostgreSQL
railway connect postgres

# Run migrations on Railway
railway run flask db upgrade
```

## ğŸ” Security Notes

- ğŸ”‘ **JWT Tokens**: All authenticated endpoints require `Authorization: Bearer <token>`
- ğŸ›¡ï¸ **API Keys**: Never commit API keys to version control
- ğŸŒ **CORS**: Configured for cross-origin requests
- ğŸ”’ **HTTPS**: Always use HTTPS in production (Railway provides this automatically)
- ğŸ“Š **Rate Limiting**: Consider implementing rate limiting for production use

## ğŸ“ˆ Production Considerations

- **Database**: Railway PostgreSQL automatically handles backups and scaling
- **Monitoring**: Use Railway's built-in monitoring and logging
- **Environment**: Set `FLASK_ENV=production` and `FLASK_DEBUG=0`
- **Scaling**: Railway supports automatic scaling based on usage
- **Custom Domain**: Configure custom domains through Railway dashboard

---

## ğŸ† Project Status & Achievements

### âœ¨ Development Excellence
- **ğŸ¯ 100% Test Coverage**: 67/67 tests passing
- **ğŸ”„ CI/CD Ready**: Automated testing and deployment
- **ğŸ“± Production Ready**: Docker containerization with multi-environment support
- **ğŸ›¡ï¸ Security First**: JWT authentication, input validation, secure API design
- **ğŸ“Š Comprehensive Logging**: Detailed error tracking and monitoring

### ğŸš€ Features Implemented
- âœ… **AI-Powered Resume Analysis** with OpenAI GPT-4 integration
- âœ… **Complete File Management System** with upload, download, processing, and deletion capabilities
- âœ… **Multi-Storage Backend** supporting local storage and Amazon S3 with seamless configuration
- âœ… **Advanced File Processing** with PDF and DOCX text extraction, language detection, and metadata analysis
- âœ… **Centralized Configuration Management** with environment-based storage and processing settings
- âœ… **Comprehensive Error Handling** with standardized error codes and user-friendly messaging
- âœ… **Multi-Format Export** (PDF, DOCX, Google Docs)
- âœ… **Google OAuth Integration** with Drive API
- âœ… **Professional Templates** with responsive design
- âœ… **Comprehensive Scoring** with detailed metrics
- âœ… **User Management** with secure authentication
- âœ… **Interactive API Documentation** with Swagger/OpenAPI

### ğŸ“Š Technical Metrics
- **Lines of Code**: 15,000+ with comprehensive documentation
- **API Endpoints**: 20+ RESTful endpoints
- **Database Models**: 8 comprehensive models with relationships
- **Service Classes**: 12 specialized services with clean architecture
- **Test Suite**: 67 comprehensive tests with mocking and integration coverage

---

## ğŸ¤ Contributing

This project follows the guidelines specified in:
- **Project Rules**: [`.github/instructions/copilot-instructions.instructions.md`](./.github/instructions/copilot-instructions.instructions.md)
- **Code Style**: PEP8 with Black formatting
- **Testing**: Pytest with comprehensive coverage requirements
- **Documentation**: Comprehensive docstrings and API documentation

### Development Workflow
1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Write tests for new functionality
4. Implement feature with proper documentation
5. Ensure all tests pass (`pytest app/tests/ -v`)
6. Submit pull request with detailed description

---

## ğŸ“ Support & Contact

- **ğŸ“š Documentation**: Check the documentation links above
- **ğŸ› Issues**: [GitHub Issues](https://github.com/Andrlulu/Resume_Modifier/issues)
- **ğŸ’¡ Feature Requests**: [GitHub Discussions](https://github.com/Andrlulu/Resume_Modifier/discussions)
- **ğŸ“§ Contact**: Create an issue for direct support

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

**ğŸ‰ Ready to optimize resumes with AI? Get started with the setup guide above!**

Made with â¤ï¸ by the Resume Modifier team
```` 